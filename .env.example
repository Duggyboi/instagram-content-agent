# LLM Configuration
# Using Ollama for local inference (no API key needed)
OLLAMA_MODEL=llama2:13b
OLLAMA_BASE_URL=http://localhost:11434

# Original OpenAI config (commented out - using Ollama instead)
# OPENAI_API_KEY=sk-your-api-key-here
# OPENAI_MODEL=gpt-4

# Agent Configuration
MAX_ITERATIONS=10
TIMEOUT=300
VERBOSE=True

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# Project Configuration
PROJECT_NAME=instagram-content-agent
ENVIRONMENT=development

# Framework Reference
FRAMEWORK_VERSION=agentic-infrastructure-framework@main

# GitHub Configuration
GITHUB_PAT=your_github_personal_access_token_here
